{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ CONFIGURATION ============\n",
    "TEAM_NAME_MAP = {\n",
    "    'ATL': 'Atlanta Hawks', 'BOS': 'Boston Celtics', 'BRK': 'Brooklyn Nets',\n",
    "    'BKN': 'Brooklyn Nets', 'CHA': 'Charlotte Hornets', 'CHI': 'Chicago Bulls',\n",
    "    'CLE': 'Cleveland Cavaliers', 'DAL': 'Dallas Mavericks', 'DEN': 'Denver Nuggets',\n",
    "    'DET': 'Detroit Pistons', 'GSW': 'Golden State Warriors', 'HOU': 'Houston Rockets',\n",
    "    'IND': 'Indiana Pacers', 'LAC': 'Los Angeles Clippers', 'LAL': 'Los Angeles Lakers',\n",
    "    'MEM': 'Memphis Grizzlies', 'MIA': 'Miami Heat', 'MIL': 'Milwaukee Bucks',\n",
    "    'MIN': 'Minnesota Timberwolves', 'NOP': 'New Orleans Pelicans', 'NYK': 'New York Knicks',\n",
    "    'OKC': 'Oklahoma City Thunder', 'ORL': 'Orlando Magic', 'PHI': 'Philadelphia 76ers',\n",
    "    'PHX': 'Phoenix Suns', 'POR': 'Portland Trail Blazers', 'SAC': 'Sacramento Kings',\n",
    "    'SAS': 'San Antonio Spurs', 'TOR': 'Toronto Raptors', 'UTA': 'Utah Jazz',\n",
    "    'WAS': 'Washington Wizards',\n",
    "    # full name mappings\n",
    "    'Detroit Pistons': 'Detroit Pistons',\n",
    "    'Indiana Pacers': 'Indiana Pacers',\n",
    "    'San Antonio Spurs': 'San Antonio Spurs',\n",
    "    'New Jersey Nets': 'New Jersey Nets',\n",
    "    'Dallas Mavericks': 'Dallas Mavericks'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_player_stats(base_path):\n",
    "    player_files = glob.glob(os.path.join(base_path, \"Player Stats Regular and Playoff\", \"*_filtered.xlsx\"))\n",
    "    dfs = []\n",
    "    \n",
    "    for file in player_files:\n",
    "        if '~$' in file:\n",
    "            continue\n",
    "            \n",
    "        season = os.path.basename(file).split('_')[0]\n",
    "        df = pd.read_excel(file)\n",
    "        df['Team'] = df['Team'].map(TEAM_NAME_MAP).fillna(df['Team'])\n",
    "        df['Season'] = season\n",
    "        \n",
    "        # select and clean relevant columns\n",
    "        player_stats = df[['Player', 'Team', 'Season', 'G', 'MP', 'FG%', '3P%', 'eFG%', 'FT%',\n",
    "                          'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']].copy()\n",
    "        \n",
    "        # handle missing values\n",
    "        for col in ['FG%', '3P%', 'eFG%', 'FT%']:\n",
    "            player_stats[col] = player_stats[col].fillna(0)  # Assume 0% if no attempts\n",
    "            \n",
    "        # fill other missing values with 0 \n",
    "        player_stats = player_stats.fillna(0)\n",
    "        \n",
    "        dfs.append(player_stats)\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_playoff_stats(base_path):\n",
    "    playoff_files = glob.glob(os.path.join(base_path, \"Actual Playoff Team Stats\", \"*__playoff_actual_team_stats.xlsx\"))\n",
    "    dfs = []\n",
    "    \n",
    "    for file in playoff_files:\n",
    "        season = os.path.basename(file).split('__')[0]\n",
    "        df = pd.read_excel(file)\n",
    "        clean_df = df.rename(columns={'Tm': 'Team', 'Rk': 'Playoff_Rank'})[['Team', 'Playoff_Rank']].copy()\n",
    "        clean_df['Team'] = clean_df['Team'].map(TEAM_NAME_MAP).fillna(clean_df['Team'])\n",
    "        clean_df['Season'] = season\n",
    "        dfs.append(clean_df)\n",
    "    \n",
    "    playoff_df = pd.concat(dfs, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # validate playoff rankings\n",
    "    for season in playoff_df['Season'].unique():\n",
    "        season_ranks = playoff_df[playoff_df['Season'] == season]['Playoff_Rank']\n",
    "        assert season_ranks.min() >= 1, f\"Invalid rank <1 in {season}\"\n",
    "        assert len(season_ranks.unique()) == len(season_ranks), f\"Duplicate ranks in {season}\"\n",
    "    \n",
    "    return playoff_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ PREPROCESSING ============\n",
    "def preprocess_data(player_df, playoff_df):\n",
    "    # team aggregation with null handling\n",
    "    def weighted_avg(values, weights):\n",
    "        mask = weights > 0\n",
    "        if mask.any():\n",
    "            return np.average(values[mask], weights=weights[mask])\n",
    "        return 0  # return 0 if no valid weights\n",
    "    \n",
    "    team_agg = player_df.groupby(['Team', 'Season']).agg({\n",
    "        'MP': 'sum',\n",
    "        'FG%': lambda x: weighted_avg(x, player_df.loc[x.index, 'G']),\n",
    "        '3P%': lambda x: weighted_avg(x, player_df.loc[x.index, 'G']),\n",
    "        'eFG%': lambda x: weighted_avg(x, player_df.loc[x.index, 'G']),\n",
    "        'FT%': lambda x: weighted_avg(x, player_df.loc[x.index, 'G']),\n",
    "        'TRB': 'sum',\n",
    "        'AST': ['sum', lambda x: x.nlargest(3).mean() if len(x) >= 3 else 0],\n",
    "        'STL': 'sum',\n",
    "        'BLK': 'sum',\n",
    "        'TOV': 'sum',\n",
    "        'PF': 'sum',\n",
    "        'PTS': ['sum', lambda x: x.nlargest(3).mean() if len(x) >= 3 else 0],\n",
    "        'G': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # flatten multi-index columns\n",
    "    team_agg.columns = [\n",
    "        'Team', 'Season', 'MP_sum', 'FG%_wt', '3P%_wt', 'eFG%_wt', 'FT%_wt',\n",
    "        'TRB_sum', 'AST_sum', 'AST_top3', 'STL_sum', 'BLK_sum', 'TOV_sum',\n",
    "        'PF_sum', 'PTS_sum', 'PTS_top3', 'G_mean', 'G_std'\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # fill any remaining null values\n",
    "    team_agg = team_agg.fillna(0)\n",
    "    \n",
    "    # merge with playoff data\n",
    "    merged = pd.merge(team_agg, playoff_df, on=['Team', 'Season'], how='inner')\n",
    "    \n",
    "    # prepare player arrays\n",
    "    player_cols = ['MP', 'FG%', '3P%', 'eFG%', 'FT%', 'TRB', 'AST', \n",
    "                   'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
    "    player_arrays = []\n",
    "    for _, row in merged.iterrows():\n",
    "        team_players = player_df[(player_df['Team'] == row['Team']) & \n",
    "                               (player_df['Season'] == row['Season'])]\n",
    "        arr = team_players[player_cols].values\n",
    "        player_arrays.append(arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # pad player arrays to uniform size\n",
    "    max_players = max(arr.shape[0] for arr in player_arrays)\n",
    "    player_arrays = np.stack([\n",
    "        np.pad(arr, ((0, max_players - arr.shape[0]), (0, 0)), \n",
    "        mode='constant', constant_values=0)\n",
    "        for arr in player_arrays\n",
    "    ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # scale player stats with null protection\n",
    "    player_scaler = StandardScaler()\n",
    "    original_shape = player_arrays.shape\n",
    "    player_arrays_reshaped = player_arrays.reshape(-1, original_shape[-1])\n",
    "    player_arrays_reshaped = np.nan_to_num(player_arrays_reshaped, nan=0)\n",
    "    player_arrays = player_scaler.fit_transform(player_arrays_reshaped).reshape(original_shape)\n",
    "    \n",
    "    # prepare team features\n",
    "    team_features = merged.drop(['Team', 'Season', 'Playoff_Rank'], axis=1).values\n",
    "    team_scaler = StandardScaler()\n",
    "    team_features = np.nan_to_num(team_features, nan=0)\n",
    "    team_features = team_scaler.fit_transform(team_features)\n",
    "    \n",
    "    # final validation\n",
    "    assert not np.isnan(player_arrays).any(), \"NaN values in player arrays\"\n",
    "    assert not np.isnan(team_features).any(), \"NaN values in team features\"\n",
    "    assert not np.isnan(merged['Playoff_Rank'].values).any(), \"NaN values in targets\"\n",
    "    \n",
    "    return player_arrays, team_features, merged['Playoff_Rank'].values, merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBADataset(Dataset):\n",
    "    def __init__(self, player_arrays, team_features, targets, original_indices=None):\n",
    "        self.player_data = torch.FloatTensor(player_arrays)\n",
    "        self.team_data = torch.FloatTensor(team_features)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "        self.original_indices = original_indices if original_indices is not None else np.arange(len(targets))\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'player_stats': self.player_data[idx],\n",
    "            'team_features': self.team_data[idx],\n",
    "            'target': self.targets[idx],\n",
    "            'original_idx': self.original_indices[idx]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
